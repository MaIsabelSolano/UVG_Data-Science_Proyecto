{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1Xi60jSGcMPH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.0.202-py3-none-any.whl.metadata (31 kB)\n",
            "Collecting tqdm\n",
            "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
            "     ---------------------------------------- 0.0/57.6 kB ? eta -:--:--\n",
            "     ---------------------------------------- 57.6/57.6 kB 3.0 MB/s eta 0:00:00\n",
            "Collecting opencv-python\n",
            "  Downloading opencv_python-4.8.1.78-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.16.0-cp310-cp310-win_amd64.whl.metadata (6.6 kB)\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.1.2-cp310-cp310-win_amd64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: Pillow in c:\\users\\usuario\\desktop\\8vo. semestre uvg 2023\\deep learning\\labs\\virtualenv\\lib\\site-packages (10.0.0)\n",
            "Collecting Pillow\n",
            "  Downloading Pillow-10.1.0-cp310-cp310-win_amd64.whl.metadata (9.6 kB)\n",
            "Collecting gdown\n",
            "  Using cached gdown-4.7.1-py3-none-any.whl (15 kB)\n",
            "Collecting aicrowd-cli\n",
            "  Downloading aicrowd_cli-0.1.15-py3-none-any.whl (51 kB)\n",
            "     ---------------------------------------- 0.0/51.1 kB ? eta -:--:--\n",
            "     ---------------------------------------- 51.1/51.1 kB ? eta 0:00:00\n",
            "Collecting matplotlib>=3.3.0 (from ultralytics)\n",
            "  Downloading matplotlib-3.8.0-cp310-cp310-win_amd64.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: numpy>=1.22.2 in c:\\users\\usuario\\desktop\\8vo. semestre uvg 2023\\deep learning\\labs\\virtualenv\\lib\\site-packages (from ultralytics) (1.25.2)\n",
            "Collecting pyyaml>=5.3.1 (from ultralytics)\n",
            "  Downloading PyYAML-6.0.1-cp310-cp310-win_amd64.whl.metadata (2.1 kB)\n",
            "Collecting requests>=2.23.0 (from ultralytics)\n",
            "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\usuario\\desktop\\8vo. semestre uvg 2023\\deep learning\\labs\\virtualenv\\lib\\site-packages (from ultralytics) (1.11.1)\n",
            "Collecting torch>=1.8.0 (from ultralytics)\n",
            "  Downloading torch-2.1.0-cp310-cp310-win_amd64.whl.metadata (24 kB)\n",
            "Collecting seaborn>=0.11.0 (from ultralytics)\n",
            "  Downloading seaborn-0.13.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: psutil in c:\\users\\usuario\\desktop\\8vo. semestre uvg 2023\\deep learning\\labs\\virtualenv\\lib\\site-packages (from ultralytics) (5.9.5)\n",
            "Collecting py-cpuinfo (from ultralytics)\n",
            "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
            "Collecting thop>=0.1.1 (from ultralytics)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\usuario\\desktop\\8vo. semestre uvg 2023\\deep learning\\labs\\virtualenv\\lib\\site-packages (from tqdm) (0.4.6)\n",
            "Collecting filelock (from torch>=1.8.0->ultralytics)\n",
            "  Downloading filelock-3.12.4-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting typing-extensions (from torch>=1.8.0->ultralytics)\n",
            "  Using cached typing_extensions-4.8.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting sympy (from torch>=1.8.0->ultralytics)\n",
            "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
            "     ---------------------------------------- 0.0/5.7 MB ? eta -:--:--\n",
            "      --------------------------------------- 0.1/5.7 MB 6.4 MB/s eta 0:00:01\n",
            "     - -------------------------------------- 0.2/5.7 MB 2.9 MB/s eta 0:00:02\n",
            "     -- ------------------------------------- 0.4/5.7 MB 3.1 MB/s eta 0:00:02\n",
            "     --- ------------------------------------ 0.5/5.7 MB 2.8 MB/s eta 0:00:02\n",
            "     ---- ----------------------------------- 0.7/5.7 MB 3.0 MB/s eta 0:00:02\n",
            "     ----- ---------------------------------- 0.8/5.7 MB 2.9 MB/s eta 0:00:02\n",
            "     ------ --------------------------------- 1.0/5.7 MB 3.1 MB/s eta 0:00:02\n",
            "     ------- -------------------------------- 1.1/5.7 MB 3.2 MB/s eta 0:00:02\n",
            "     --------- ------------------------------ 1.3/5.7 MB 3.3 MB/s eta 0:00:02\n",
            "     ---------- ----------------------------- 1.5/5.7 MB 3.3 MB/s eta 0:00:02\n",
            "     ----------- ---------------------------- 1.6/5.7 MB 3.3 MB/s eta 0:00:02\n",
            "     ------------ --------------------------- 1.8/5.7 MB 3.4 MB/s eta 0:00:02\n",
            "     -------------- ------------------------- 2.0/5.7 MB 3.5 MB/s eta 0:00:02\n",
            "     --------------- ------------------------ 2.2/5.7 MB 3.6 MB/s eta 0:00:01\n",
            "     ----------------- ---------------------- 2.4/5.7 MB 3.7 MB/s eta 0:00:01\n",
            "     ------------------ --------------------- 2.6/5.7 MB 3.8 MB/s eta 0:00:01\n",
            "     -------------------- ------------------- 2.9/5.7 MB 3.8 MB/s eta 0:00:01\n",
            "     --------------------- ------------------ 3.1/5.7 MB 3.8 MB/s eta 0:00:01\n",
            "     ---------------------- ----------------- 3.2/5.7 MB 3.7 MB/s eta 0:00:01\n",
            "     ----------------------- ---------------- 3.4/5.7 MB 3.8 MB/s eta 0:00:01\n",
            "     ------------------------ --------------- 3.5/5.7 MB 3.7 MB/s eta 0:00:01\n",
            "     ------------------------- -------------- 3.7/5.7 MB 3.7 MB/s eta 0:00:01\n",
            "     ------------------------- -------------- 3.7/5.7 MB 3.6 MB/s eta 0:00:01\n",
            "     -------------------------- ------------- 3.8/5.7 MB 3.6 MB/s eta 0:00:01\n",
            "     --------------------------- ------------ 3.9/5.7 MB 3.5 MB/s eta 0:00:01\n",
            "     --------------------------- ------------ 3.9/5.7 MB 3.4 MB/s eta 0:00:01\n",
            "     ---------------------------- ----------- 4.0/5.7 MB 3.3 MB/s eta 0:00:01\n",
            "     ---------------------------- ----------- 4.1/5.7 MB 3.2 MB/s eta 0:00:01\n",
            "     ----------------------------- ---------- 4.2/5.7 MB 3.1 MB/s eta 0:00:01\n",
            "     ----------------------------- ---------- 4.3/5.7 MB 3.1 MB/s eta 0:00:01\n",
            "     ------------------------------ --------- 4.3/5.7 MB 3.0 MB/s eta 0:00:01\n",
            "     ------------------------------ --------- 4.4/5.7 MB 3.0 MB/s eta 0:00:01\n",
            "     ------------------------------- -------- 4.5/5.7 MB 2.9 MB/s eta 0:00:01\n",
            "     ------------------------------- -------- 4.5/5.7 MB 2.9 MB/s eta 0:00:01\n",
            "     -------------------------------- ------- 4.6/5.7 MB 2.8 MB/s eta 0:00:01\n",
            "     -------------------------------- ------- 4.7/5.7 MB 2.8 MB/s eta 0:00:01\n",
            "     --------------------------------- ------ 4.8/5.7 MB 2.8 MB/s eta 0:00:01\n",
            "     ---------------------------------- ----- 4.9/5.7 MB 2.7 MB/s eta 0:00:01\n",
            "     ---------------------------------- ----- 5.0/5.7 MB 2.7 MB/s eta 0:00:01\n",
            "     ----------------------------------- ---- 5.1/5.7 MB 2.7 MB/s eta 0:00:01\n",
            "     ----------------------------------- ---- 5.1/5.7 MB 2.7 MB/s eta 0:00:01\n",
            "     ------------------------------------ --- 5.2/5.7 MB 2.6 MB/s eta 0:00:01\n",
            "     ------------------------------------ --- 5.3/5.7 MB 2.6 MB/s eta 0:00:01\n",
            "     ------------------------------------- -- 5.4/5.7 MB 2.6 MB/s eta 0:00:01\n",
            "     -------------------------------------- - 5.6/5.7 MB 2.6 MB/s eta 0:00:01\n",
            "     ---------------------------------------  5.7/5.7 MB 2.5 MB/s eta 0:00:01\n",
            "     ---------------------------------------  5.7/5.7 MB 2.5 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 5.7/5.7 MB 2.5 MB/s eta 0:00:00\n",
            "Requirement already satisfied: networkx in c:\\users\\usuario\\desktop\\8vo. semestre uvg 2023\\deep learning\\labs\\virtualenv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1)\n",
            "Collecting jinja2 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "     ---------------------------------------- 0.0/133.1 kB ? eta -:--:--\n",
            "     --------------------------- ----------- 92.2/133.1 kB 2.6 MB/s eta 0:00:01\n",
            "     -------------------------------------- 133.1/133.1 kB 1.6 MB/s eta 0:00:00\n",
            "Collecting fsspec (from torch>=1.8.0->ultralytics)\n",
            "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\usuario\\desktop\\8vo. semestre uvg 2023\\deep learning\\labs\\virtualenv\\lib\\site-packages (from pandas) (2.8.2)\n",
            "Collecting pytz>=2020.1 (from pandas)\n",
            "  Using cached pytz-2023.3.post1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.1 (from pandas)\n",
            "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
            "     ---------------------------------------- 0.0/341.8 kB ? eta -:--:--\n",
            "     ------------ ------------------------- 112.6/341.8 kB 3.3 MB/s eta 0:00:01\n",
            "     --------------------- ---------------- 194.6/341.8 kB 2.4 MB/s eta 0:00:01\n",
            "     ---------------------------------- --- 307.2/341.8 kB 2.1 MB/s eta 0:00:01\n",
            "     -------------------------------------- 341.8/341.8 kB 1.9 MB/s eta 0:00:00\n",
            "Requirement already satisfied: six in c:\\users\\usuario\\desktop\\8vo. semestre uvg 2023\\deep learning\\labs\\virtualenv\\lib\\site-packages (from gdown) (1.16.0)\n",
            "Collecting beautifulsoup4 (from gdown)\n",
            "  Downloading beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
            "     ---------------------------------------- 0.0/143.0 kB ? eta -:--:--\n",
            "     --------------------------- ---------- 102.4/143.0 kB 2.0 MB/s eta 0:00:01\n",
            "     -------------------------------------- 143.0/143.0 kB 1.7 MB/s eta 0:00:00\n",
            "Collecting click<8,>=7.1.2 (from aicrowd-cli)\n",
            "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
            "     ---------------------------------------- 0.0/82.8 kB ? eta -:--:--\n",
            "     ---------------------------------------- 82.8/82.8 kB 2.3 MB/s eta 0:00:00\n",
            "Collecting GitPython==3.1.18 (from aicrowd-cli)\n",
            "  Downloading GitPython-3.1.18-py3-none-any.whl (170 kB)\n",
            "     ---------------------------------------- 0.0/170.1 kB ? eta -:--:--\n",
            "     ------------------------- ------------ 112.6/170.1 kB 3.3 MB/s eta 0:00:01\n",
            "     -------------------------------------- 170.1/170.1 kB 2.0 MB/s eta 0:00:00\n",
            "Collecting requests-toolbelt<1,>=0.9.1 (from aicrowd-cli)\n",
            "  Downloading requests_toolbelt-0.10.1-py2.py3-none-any.whl (54 kB)\n",
            "     ---------------------------------------- 0.0/54.5 kB ? eta -:--:--\n",
            "     ---------------------------------------- 54.5/54.5 kB 1.4 MB/s eta 0:00:00\n",
            "Collecting rich<11,>=10.0.0 (from aicrowd-cli)\n",
            "  Downloading rich-10.16.2-py3-none-any.whl (214 kB)\n",
            "     ---------------------------------------- 0.0/214.4 kB ? eta -:--:--\n",
            "     --------------------- ---------------- 122.9/214.4 kB 3.6 MB/s eta 0:00:01\n",
            "     ------------------------------------ - 204.8/214.4 kB 2.5 MB/s eta 0:00:01\n",
            "     -------------------------------------- 214.4/214.4 kB 2.2 MB/s eta 0:00:00\n",
            "Collecting toml<1,>=0.10.2 (from aicrowd-cli)\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting pyzmq==22.1.0 (from aicrowd-cli)\n",
            "  Downloading pyzmq-22.1.0.tar.gz (1.2 MB)\n",
            "     ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
            "     --- ------------------------------------ 0.1/1.2 MB 3.3 MB/s eta 0:00:01\n",
            "     ------ --------------------------------- 0.2/1.2 MB 2.4 MB/s eta 0:00:01\n",
            "     --------- ------------------------------ 0.3/1.2 MB 2.4 MB/s eta 0:00:01\n",
            "     ------------- -------------------------- 0.4/1.2 MB 2.3 MB/s eta 0:00:01\n",
            "     ----------------- ---------------------- 0.5/1.2 MB 2.3 MB/s eta 0:00:01\n",
            "     -------------------- ------------------- 0.6/1.2 MB 2.2 MB/s eta 0:00:01\n",
            "     ----------------------- ---------------- 0.7/1.2 MB 2.3 MB/s eta 0:00:01\n",
            "     --------------------------- ------------ 0.8/1.2 MB 2.3 MB/s eta 0:00:01\n",
            "     ------------------------------ --------- 0.9/1.2 MB 2.3 MB/s eta 0:00:01\n",
            "     ---------------------------------- ----- 1.1/1.2 MB 2.2 MB/s eta 0:00:01\n",
            "     -------------------------------------- - 1.2/1.2 MB 2.2 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 1.2/1.2 MB 2.2 MB/s eta 0:00:00\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'error'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  error: subprocess-exited-with-error\n",
            "  \n",
            "  × Getting requirements to build wheel did not run successfully.\n",
            "  │ exit code: 1\n",
            "  ╰─> [23 lines of output]\n",
            "      Traceback (most recent call last):\n",
            "        File \"c:\\Users\\Usuario\\Desktop\\8vo. Semestre UVG 2023\\Deep Learning\\Labs\\virtualENV\\lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
            "          main()\n",
            "        File \"c:\\Users\\Usuario\\Desktop\\8vo. Semestre UVG 2023\\Deep Learning\\Labs\\virtualENV\\lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
            "          json_out['return_val'] = hook(**hook_input['kwargs'])\n",
            "        File \"c:\\Users\\Usuario\\Desktop\\8vo. Semestre UVG 2023\\Deep Learning\\Labs\\virtualENV\\lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 118, in get_requires_for_build_wheel\n",
            "          return hook(config_settings)\n",
            "        File \"C:\\Users\\Usuario\\AppData\\Local\\Temp\\pip-build-env-yd9bipme\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 355, in get_requires_for_build_wheel\n",
            "          return self._get_build_requires(config_settings, requirements=['wheel'])\n",
            "        File \"C:\\Users\\Usuario\\AppData\\Local\\Temp\\pip-build-env-yd9bipme\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 325, in _get_build_requires\n",
            "          self.run_setup()\n",
            "        File \"C:\\Users\\Usuario\\AppData\\Local\\Temp\\pip-build-env-yd9bipme\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 507, in run_setup\n",
            "          super(_BuildMetaLegacyBackend, self).run_setup(setup_script=setup_script)\n",
            "        File \"C:\\Users\\Usuario\\AppData\\Local\\Temp\\pip-build-env-yd9bipme\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 341, in run_setup\n",
            "          exec(code, locals())\n",
            "        File \"<string>\", line 140, in <module>\n",
            "        File \"C:\\Users\\Usuario\\AppData\\Local\\Temp\\pip-install-3rg6txem\\pyzmq_2ae96ffa72ca45928047edc5999d1e57\\buildutils\\misc.py\", line 83, in locate_vcredist_dir\n",
            "          vcvars = msvc.msvc14_get_vc_env(get_platform())\n",
            "        File \"C:\\Users\\Usuario\\AppData\\Local\\Temp\\pip-build-env-yd9bipme\\overlay\\Lib\\site-packages\\setuptools\\msvc.py\", line 233, in msvc14_get_vc_env\n",
            "          return _msvc14_get_vc_env(plat_spec)\n",
            "        File \"C:\\Users\\Usuario\\AppData\\Local\\Temp\\pip-build-env-yd9bipme\\overlay\\Lib\\site-packages\\setuptools\\msvc.py\", line 190, in _msvc14_get_vc_env\n",
            "          raise distutils.errors.DistutilsPlatformError(\"Unable to find vcvarsall.bat\")\n",
            "      setuptools._distutils.errors.DistutilsPlatformError: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
            "      [end of output]\n",
            "  \n",
            "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "error: subprocess-exited-with-error\n",
            "\n",
            "× Getting requirements to build wheel did not run successfully.\n",
            "│ exit code: 1\n",
            "╰─> See above for output.\n",
            "\n",
            "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ultralytics\n",
            "  Using cached ultralytics-8.0.202-py3-none-any.whl.metadata (31 kB)\n",
            "Collecting tqdm\n",
            "  Using cached tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting opencv-python\n",
            "  Using cached opencv_python-4.8.1.78-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
            "Collecting torchvision\n",
            "  Using cached torchvision-0.16.0-cp310-cp310-win_amd64.whl.metadata (6.6 kB)\n",
            "Collecting pandas\n",
            "  Using cached pandas-2.1.2-cp310-cp310-win_amd64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: Pillow in c:\\users\\usuario\\desktop\\8vo. semestre uvg 2023\\deep learning\\labs\\virtualenv\\lib\\site-packages (10.0.0)\n",
            "Collecting Pillow\n",
            "  Using cached Pillow-10.1.0-cp310-cp310-win_amd64.whl.metadata (9.6 kB)\n",
            "Collecting gdown\n",
            "  Using cached gdown-4.7.1-py3-none-any.whl (15 kB)\n",
            "Collecting aicrowd-cli\n",
            "  Using cached aicrowd_cli-0.1.15-py3-none-any.whl (51 kB)\n",
            "Collecting matplotlib>=3.3.0 (from ultralytics)\n",
            "  Using cached matplotlib-3.8.0-cp310-cp310-win_amd64.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: numpy>=1.22.2 in c:\\users\\usuario\\desktop\\8vo. semestre uvg 2023\\deep learning\\labs\\virtualenv\\lib\\site-packages (from ultralytics) (1.25.2)\n",
            "Collecting pyyaml>=5.3.1 (from ultralytics)\n",
            "  Using cached PyYAML-6.0.1-cp310-cp310-win_amd64.whl.metadata (2.1 kB)\n",
            "Collecting requests>=2.23.0 (from ultralytics)\n",
            "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\usuario\\desktop\\8vo. semestre uvg 2023\\deep learning\\labs\\virtualenv\\lib\\site-packages (from ultralytics) (1.11.1)\n",
            "Collecting torch>=1.8.0 (from ultralytics)\n",
            "  Using cached torch-2.1.0-cp310-cp310-win_amd64.whl.metadata (24 kB)\n",
            "Collecting seaborn>=0.11.0 (from ultralytics)\n",
            "  Using cached seaborn-0.13.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: psutil in c:\\users\\usuario\\desktop\\8vo. semestre uvg 2023\\deep learning\\labs\\virtualenv\\lib\\site-packages (from ultralytics) (5.9.5)\n",
            "Collecting py-cpuinfo (from ultralytics)\n",
            "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
            "Collecting thop>=0.1.1 (from ultralytics)\n",
            "  Using cached thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\usuario\\desktop\\8vo. semestre uvg 2023\\deep learning\\labs\\virtualenv\\lib\\site-packages (from tqdm) (0.4.6)\n",
            "Collecting filelock (from torch>=1.8.0->ultralytics)\n",
            "  Using cached filelock-3.12.4-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting typing-extensions (from torch>=1.8.0->ultralytics)\n",
            "  Using cached typing_extensions-4.8.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting sympy (from torch>=1.8.0->ultralytics)\n",
            "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
            "Requirement already satisfied: networkx in c:\\users\\usuario\\desktop\\8vo. semestre uvg 2023\\deep learning\\labs\\virtualenv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1)\n",
            "Collecting jinja2 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "Collecting fsspec (from torch>=1.8.0->ultralytics)\n",
            "  Using cached fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\usuario\\desktop\\8vo. semestre uvg 2023\\deep learning\\labs\\virtualenv\\lib\\site-packages (from pandas) (2.8.2)\n",
            "Collecting pytz>=2020.1 (from pandas)\n",
            "  Using cached pytz-2023.3.post1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.1 (from pandas)\n",
            "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
            "Requirement already satisfied: six in c:\\users\\usuario\\desktop\\8vo. semestre uvg 2023\\deep learning\\labs\\virtualenv\\lib\\site-packages (from gdown) (1.16.0)\n",
            "Collecting beautifulsoup4 (from gdown)\n",
            "  Using cached beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
            "Collecting click<8,>=7.1.2 (from aicrowd-cli)\n",
            "  Using cached click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
            "Collecting GitPython==3.1.18 (from aicrowd-cli)\n",
            "  Using cached GitPython-3.1.18-py3-none-any.whl (170 kB)\n",
            "Collecting requests-toolbelt<1,>=0.9.1 (from aicrowd-cli)\n",
            "  Using cached requests_toolbelt-0.10.1-py2.py3-none-any.whl (54 kB)\n",
            "Collecting rich<11,>=10.0.0 (from aicrowd-cli)\n",
            "  Using cached rich-10.16.2-py3-none-any.whl (214 kB)\n",
            "Collecting toml<1,>=0.10.2 (from aicrowd-cli)\n",
            "  Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting pyzmq==22.1.0 (from aicrowd-cli)\n",
            "  Using cached pyzmq-22.1.0.tar.gz (1.2 MB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'error'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  error: subprocess-exited-with-error\n",
            "  \n",
            "  × Getting requirements to build wheel did not run successfully.\n",
            "  │ exit code: 1\n",
            "  ╰─> [23 lines of output]\n",
            "      Traceback (most recent call last):\n",
            "        File \"c:\\Users\\Usuario\\Desktop\\8vo. Semestre UVG 2023\\Deep Learning\\Labs\\virtualENV\\lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
            "          main()\n",
            "        File \"c:\\Users\\Usuario\\Desktop\\8vo. Semestre UVG 2023\\Deep Learning\\Labs\\virtualENV\\lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
            "          json_out['return_val'] = hook(**hook_input['kwargs'])\n",
            "        File \"c:\\Users\\Usuario\\Desktop\\8vo. Semestre UVG 2023\\Deep Learning\\Labs\\virtualENV\\lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 118, in get_requires_for_build_wheel\n",
            "          return hook(config_settings)\n",
            "        File \"C:\\Users\\Usuario\\AppData\\Local\\Temp\\pip-build-env-fzb3poir\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 355, in get_requires_for_build_wheel\n",
            "          return self._get_build_requires(config_settings, requirements=['wheel'])\n",
            "        File \"C:\\Users\\Usuario\\AppData\\Local\\Temp\\pip-build-env-fzb3poir\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 325, in _get_build_requires\n",
            "          self.run_setup()\n",
            "        File \"C:\\Users\\Usuario\\AppData\\Local\\Temp\\pip-build-env-fzb3poir\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 507, in run_setup\n",
            "          super(_BuildMetaLegacyBackend, self).run_setup(setup_script=setup_script)\n",
            "        File \"C:\\Users\\Usuario\\AppData\\Local\\Temp\\pip-build-env-fzb3poir\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 341, in run_setup\n",
            "          exec(code, locals())\n",
            "        File \"<string>\", line 140, in <module>\n",
            "        File \"C:\\Users\\Usuario\\AppData\\Local\\Temp\\pip-install-7193eogi\\pyzmq_bcbfafb698134f9b91c40759d971de4d\\buildutils\\misc.py\", line 83, in locate_vcredist_dir\n",
            "          vcvars = msvc.msvc14_get_vc_env(get_platform())\n",
            "        File \"C:\\Users\\Usuario\\AppData\\Local\\Temp\\pip-build-env-fzb3poir\\overlay\\Lib\\site-packages\\setuptools\\msvc.py\", line 233, in msvc14_get_vc_env\n",
            "          return _msvc14_get_vc_env(plat_spec)\n",
            "        File \"C:\\Users\\Usuario\\AppData\\Local\\Temp\\pip-build-env-fzb3poir\\overlay\\Lib\\site-packages\\setuptools\\msvc.py\", line 190, in _msvc14_get_vc_env\n",
            "          raise distutils.errors.DistutilsPlatformError(\"Unable to find vcvarsall.bat\")\n",
            "      setuptools._distutils.errors.DistutilsPlatformError: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
            "      [end of output]\n",
            "  \n",
            "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "error: subprocess-exited-with-error\n",
            "\n",
            "× Getting requirements to build wheel did not run successfully.\n",
            "│ exit code: 1\n",
            "╰─> See above for output.\n",
            "\n",
            "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
          ]
        }
      ],
      "source": [
        "!pip install -U ultralytics tqdm opencv-python torchvision pandas Pillow gdown aicrowd-cli"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow\n",
            "  Obtaining dependency information for tensorflow from https://files.pythonhosted.org/packages/1c/c3/17c6aa1dd5bc8cea5bf00d0c3a021a5dd1680c250861cc877a7e556e4b9b/tensorflow-2.14.0-cp310-cp310-win_amd64.whl.metadata\n",
            "  Using cached tensorflow-2.14.0-cp310-cp310-win_amd64.whl.metadata (3.3 kB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not find a version that satisfies the requirement cv2 (from versions: none)\n",
            "ERROR: No matching distribution found for cv2\n",
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow cv2 numpy torch sklearn streamlit joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Z9RcVLrb6Yn"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tensorflow'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\Usuario\\Desktop\\8vo. Semestre UVG 2023\\Data Science\\Test_Proyecto\\Modelo_V2.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Desktop/8vo.%20Semestre%20UVG%202023/Data%20Science/Test_Proyecto/Modelo_V2.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Desktop/8vo.%20Semestre%20UVG%202023/Data%20Science/Test_Proyecto/Modelo_V2.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mimport\u001b[39;00m keras\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Desktop/8vo.%20Semestre%20UVG%202023/Data%20Science/Test_Proyecto/Modelo_V2.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m layers\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from timeit import default_timer as timer\n",
        "from tqdm.auto import tqdm\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import streamlit as st\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KkoHWDUIcf1-"
      },
      "outputs": [],
      "source": [
        "!aicrowd dataset download --challenge mosquitoalert-challenge-2023"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETL10Mfick1N"
      },
      "outputs": [],
      "source": [
        "!unzip -qq phase2_train_v0.zip -d test_images/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCjZWOSocq0e"
      },
      "outputs": [],
      "source": [
        "!mv phase2_train_v0.csv images_train.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DHndJRvceTa"
      },
      "outputs": [],
      "source": [
        "csv_file = 'test_images/images_train.csv'\n",
        "df = pd.read_csv(csv_file)\n",
        "\n",
        "# Shuffle the dataframe\n",
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "def load_and_preprocess_images(image_paths, target_size):\n",
        "    images = []\n",
        "    x = 0\n",
        "    for path in image_paths:\n",
        "        print(x)\n",
        "        x+=1\n",
        "        image = cv2.imread(\"final/\"+path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Ensure images are in RGB format\n",
        "        image = cv2.resize(image, target_size)\n",
        "        image = image / 255.0  # Normalize pixel values to [0, 1]\n",
        "        images.append(image)\n",
        "\n",
        "    return np.array(images)\n",
        "\n",
        "# Split the data into train, validation, and test sets\n",
        "train_size = 0.7\n",
        "validation_size = 0.15\n",
        "test_size = 0.15\n",
        "\n",
        "X = load_and_preprocess_images(df['img_fName'], target_size=(64, 64))\n",
        "y = LabelBinarizer().fit_transform(df['class_label'])\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=1 - train_size, random_state=42)\n",
        "X_validation, X_test, y_validation, y_test = train_test_split(X_temp, y_temp, test_size=test_size / (test_size + validation_size), random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTiBDbxLb6Yu"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow(X_train, y_train, batch_size=batch_size)\n",
        "\n",
        "validation_datagen = ImageDataGenerator()\n",
        "\n",
        "validation_generator = validation_datagen.flow(X_validation, y_validation, batch_size=batch_size)\n",
        "\n",
        "test_datagen = ImageDataGenerator()\n",
        "\n",
        "test_generator = test_datagen.flow(X_test, y_test, batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cg4Uk2tnb6Yx"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Create a sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Convolutional layers\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Flatten the output for the fully connected layers\n",
        "model.add(Flatten())\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))  # Adding dropout for regularization\n",
        "model.add(Dense(6, activation='softmax'))  # Replace 'number_of_classes' with the actual number of classes in your dataset\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZQMHmCPb6Yz"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "model.fit(train_generator, epochs=50, validation_data=validation_generator)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "\n",
        "print(f'Test accuracy: {test_accuracy * 100:.2f}%')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8GuSaLib6Y0"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow(X_train, y_train, batch_size=batch_size)\n",
        "\n",
        "validation_datagen = ImageDataGenerator()\n",
        "\n",
        "validation_generator = validation_datagen.flow(X_validation, y_validation, batch_size=batch_size)\n",
        "\n",
        "test_datagen = ImageDataGenerator()\n",
        "\n",
        "test_generator = test_datagen.flow(X_test, y_test, batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSTzprNkb6Y2"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "# Create a sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Convolutional layers\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Flatten the output for the fully connected layers\n",
        "model.add(Flatten())\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))  # Adding dropout for regularization\n",
        "model.add(Dense(6, activation='softmax'))  # Replace 'number_of_classes' with the actual number of classes in your dataset\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "weM0cj2Rb6Y4"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "model.fit(train_generator, epochs=20, validation_data=validation_generator)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "\n",
        "print(f'Test accuracy: {test_accuracy * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Y32oA2KdPiD"
      },
      "outputs": [],
      "source": [
        "# Se guarda el modelo\n",
        "joblib.dump(model, \"mosquitos.sav\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "virtualenv",
      "language": "python",
      "name": "virtualenv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
